{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6187e579-e06d-462b-9873-af311aa00747",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "#Union() : combaining two or more DataFrames which is having same sturture and schema\n",
    "#UnionByName() : combaining two or more DataFrames having different schema and takes param #allowMissingColumns = True\n",
    "\n",
    "ame1 = spark.createDataFrame([(\"bob\",42),(\"lisa\",32)],[\"first name\",\"age\"])\n",
    "col1 = spark.createDataFrame([(\"maria\",20),(\"camlin\",35)],[\"first name\",\"age\"])\n",
    "ame1.show()\n",
    "col1.show()\n",
    "\n",
    "result = ame1.union(col1)\n",
    "result.show()\n",
    "\n",
    "\n",
    "details = [(1,'krishna','IT','male')]\n",
    "column = ['id','name','department','gender']\n",
    "\n",
    "details1 = [(1,'krishna','IT','1000')]\n",
    "column1 = ['id','name','department','salary']\n",
    "\n",
    "\n",
    "df1 = spark.createDataFrame(details,column)\n",
    "df2 = spark.createDataFrame(details1,column1)\n",
    "df1.show()\n",
    "df2.show()\n",
    "\n",
    "df3 = df1.union(df2)\n",
    "df3.show()\n",
    "\n",
    "df1.unionByName(df2,allowMissingColumns=True).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40926009-24bc-4122-b0a1-b99da2cd3809",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "#Eample 2\n",
    "dataframe1 = spark.createDataFrame([('James',87.33),('Anna',93.25),('Anita',87.48)],['name','OverallPercentage'])\n",
    "dataframe2 = spark.createDataFrame([('Maria1',94.43),('Anna1',94.53),('Anita1',94.48)],['name','OverallPercentage'])\n",
    "dataframe1.show()\n",
    "dataframe2.show()\n",
    "\n",
    "dataframe1.union(dataframe2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c0e995f-0b98-40d5-8a36-47b1707315ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "#UnionBYName: combaine two or more dataframes which have doffernce schema because its conbaine data by name not by order of column\n",
    "d1 = spark.createDataFrame([(\"maria\",20),(\"camlin\",35)],[\"first name\",\"age\"])\n",
    "df2 = spark.createDataFrame([(20,\"maria\"),(35,\"camlin\")],[\"age\",\"first name\"])\n",
    "d1.show()\n",
    "df2.show()\n",
    "\n",
    "d1.unionByName(df2,allowMissingColumns=True).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "prac_1",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
